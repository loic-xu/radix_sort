---
title: 'Projet 6 : Radix sort'
author: "Adèle BERGER, Hajar LAMTAAI, Loïc XU"
output:
  pdf_document: default
  html_document: default
---

# Introduction

Pour ce projet, on va comparer les performances du Radix sort au Merge sort qui est en $O(n \log n)$. On va analyser la complexité de ces algorithmes dans différents scénarios et étudier leur comportement à travers des simulations. On va aussi regarder quand il est préférable d'utiliser l'un par rapport à l'autre. 

# Présentation du problème

Le problème à résoudre est de trier une liste d'éléments. Les algorithmes classiques de tri comme le Merge sort ont une complexité de $O(n \log n)$. On y pense rarement, mais certains algorithmes de tri comme le Radix sort ont une complexité en temps linéaire sous certaines conditions. On va présenter l'algorithme et analyser sa complexité.

# Difficulté algorithmique

## Problème combinatoire

Le problème de tri consiste à réorganiser un ensemble d'éléments selon un ordre donné, souvent croissant. C'est un problème combinatoire classique qui apparaît fréquemment dans les algorithmes de traitement de données. De nombreux algorithmes de tri utilisent des comparaisons entre les éléments pour déterminer leur ordre. Selon l'algorithme choisi, la complexité et l'efficacité peuvent varier. La difficulté est que le temps requis pour trier une liste dépend généralement de $n \log(n)$, ce qui peut vite exploser. On souhaiterait donc réduire la complexité temporelle.

## Solution naïve

La solution naïve utilisée dans ce projet est celle du Merge sort. C'est un algorithme de tri basé sur la stratégie diviser pour régner. Le principe de cet algorithme consiste à diviser récursivement le tableau en deux sous-tableaux jusqu'à ce que chaque sous-tableau contienne un seul élément, puis à fusionner ces sous-tableaux triés pour obtenir un tableau final trié. La fusion des sous-tableaux se fait en comparant les éléments les plus petits de chaque sous-tableau et en les insérant dans un tableau temporaire dans l'ordre croissant. Ce processus est répété jusqu'à ce que tous les sous-tableaux soient fusionnés en un seul tableau trié.

L'algorithme a une complexité en $O(n \log n)$, ce qui en fait un choix efficace pour des ensembles de données de taille moyenne à grande. Cependant, il présente une complexité en espace de $O(n)$, car un tableau temporaire est utilisé pendant la fusion. Bien qu'il soit plus gourmand en mémoire que certains autres algorithmes, sa stabilité et sa complexité prévisible en font une solution robuste pour trier de manière fiable et efficace.

## Limites avec R et C++

Les temps de calcul augmentent rapidement avec la taille des données, en particulier pour les algorithmes de tri basés sur des comparaisons. En R, notre implémentation du tri fusion reste raisonnablement efficace jusqu’à \(10^7\) éléments (environ 72 secondes sur nos machines). En revanche, au-delà de \(10^8\), les performances se dégradent fortement, avec un temps d’exécution qui dépasse les 15 minutes.

En comparaison, une implémentation en C++ se révèle nettement plus performante : trier \(10^7\) éléments prend environ 3 secondes, \(10^8\) éléments environ 32 secondes, et \(10^9\) éléments environ 6 minutes. Cela met en évidence l’intérêt d’utiliser des langages compilés pour le traitement de grandes quantités de données.

# Solution améliorée moderne

## Présentation de la stratégie algorithmique

La solution améliorée que nous proposons repose sur l'algorithme **Radix Sort**. Ce dernier trie les éléments en procédant chiffre par chiffre. Il est aussi appelé tri par base. L'algorithme est particulièrement efficace lorsque les éléments à trier sont des entiers avec pas beaucoup de chiffres. Radix Sort peut atteindre une complexité linéaire $O(n)$ dans le cas idéal.





```{r, echo=FALSE}
library(M2algorithmique)
```

# En R
```{r, echo=FALSE}
n <- 10^7
vec <- sample(1:100, n, replace = TRUE)
start_time <- Sys.time()
sorted_fusion <- tri_fusion(vec)
end_time <- Sys.time()
print(as.numeric(difftime(end_time, start_time, units = "secs")))
```

# En C++
```{r}
n <- 10^9
vec <- sample(1:100, n, replace = TRUE)
start_time <- Sys.time()
sorted_fusion <- tri_fusion_Rcpp(vec)
end_time <- Sys.time()
print(as.numeric(difftime(end_time, start_time, units = "secs")))
```




```{r, echo=FALSE}

# Comparaison des performances
set.seed(42)
n <- 10000
sizes <- seq(from = 100, to = n, length.out = 50)

times_fusion <- numeric(length(sizes))
times_radix <- numeric(length(sizes))

for (i in seq_along(sizes)) {
  vec <- sample(1:100, sizes[i], replace = TRUE)
  
  # Temps pour le tri fusion
  start_time <- Sys.time()
  sorted_fusion <- tri_fusion(vec)
  end_time <- Sys.time()
  times_fusion[i] <- as.numeric(difftime(end_time, start_time, units = "secs"))
  
  # Temps pour le tri par base
  start_time <- Sys.time()
  sorted_radix <- tri_base(vec)
  end_time <- Sys.time()
  times_radix[i] <- as.numeric(difftime(end_time, start_time, units = "secs"))
}

# Tracer un graphique avec l'axe X en échelle logarithmique
plot(sizes, times_fusion, type = "o", log = "x", col = "red", 
     xlab = "Taille du vecteur (log)", ylab = "Temps (s)", 
     main = "Comparaison des performances des algorithmes")


lines(sizes, times_radix, type = "o", col = "blue", pch = 16)
legend("topleft", legend = c("Tri fusion", "Tri par base"), col = c("red", "blue"), pch = 16)

```


```{r, echo=FALSE}
# Ajustement de la régression linéaire pour le tri par base
model_radix <- lm(times_radix ~ sizes)

# Affichage du nuage de points
plot(sizes, times_radix, col = "blue", pch = 16, 
     xlab = "Taille du vecteur", ylab = "Temps (s)", 
     main = "Régression linéaire Tri par Base (O(n))")

# Ajout de la droite de régression
abline(model_radix, col = "black", lwd = 2)


```

```{r}
set.seed(42)
n <- 100  # Taille des listes
k_values <- 1:15  # Valeurs de k

times_fusion <- numeric(length(k_values))
times_radix <- numeric(length(k_values))

for (k in k_values) {
  # Générer une liste d'entiers entre 0 et 10^k - 1
  vec <- sample((10^(k-1) - 1):(10^k - 1), n, replace = TRUE)
  
  # Temps pour le tri fusion O(n log n)
  start_time <- Sys.time()
  sorted_fusion <- tri_fusion(vec)
  end_time <- Sys.time()
  times_fusion[k] <- as.numeric(difftime(end_time, start_time, units = "secs"))
  
  # Temps pour le tri par base O(n k)
  start_time <- Sys.time()
  sorted_radix <- tri_base(vec)
  end_time <- Sys.time()
  times_radix[k] <- as.numeric(difftime(end_time, start_time, units = "secs"))
}

# Tracer les performances
plot(k_values, times_fusion, type = "o", col = "red", xlab = "Nombre de chiffres k", 
     ylab = "Temps (s)", main = "Complexité des tris en fonction de k", pch = 16, ylim = range(c(times_fusion, times_radix)))

lines(k_values, times_radix, type = "o", col = "blue", pch = 16)

legend("topleft", legend = c("Tri fusion O(n log n)", "Tri par base O(n k)"), 
       col = c("red", "blue"), pch = 16)


```


```{r}
set.seed(42)
n <- 1000   # Taille des listes
k_values <- 1:15  # Valeurs de k

times_fusion <- numeric(length(k_values))
times_radix <- numeric(length(k_values))

for (k in k_values) {
  # Générer une liste d'entiers entre 0 et 10^k - 1
  vec <- sample((10^(k-1) - 1):(10^k - 1), n, replace = TRUE)
  
  # Temps pour le tri fusion O(n log n)
  start_time <- Sys.time()
  sorted_fusion <- tri_fusion(vec)
  end_time <- Sys.time()
  times_fusion[k] <- as.numeric(difftime(end_time, start_time, units = "secs"))
  
  # Temps pour le tri par base O(n k)
  start_time <- Sys.time()
  sorted_radix <- tri_base(vec)
  end_time <- Sys.time()
  times_radix[k] <- as.numeric(difftime(end_time, start_time, units = "secs"))
}

# Tracer les performances
plot(k_values, times_fusion, type = "o", col = "red", xlab = "Nombre de chiffres k", 
     ylab = "Temps (s)", main = "Complexité des tris en fonction de k", pch = 16, ylim = range(c(times_fusion, times_radix)))

lines(k_values, times_radix, type = "o", col = "blue", pch = 16)

legend("topleft", legend = c("Tri fusion O(n log n)", "Tri par base O(n k)"), 
       col = c("red", "blue"), pch = 16)
```

